Bước 1: Load Dataset & Precompute Embeddings

Load ảnh từ data/

Với mỗi ảnh:

Resize / normalize

Chạy CLIP image encoder → lấy embedding vector

Lưu embedding vào FAISS index

Lưu metadata (filename, category, tags, path) vào MongoDB

Notes:

FAISS index nên lưu ra file (index.faiss) để load lại, không build lại mỗi lần chạy

Metadata: dictionary/json → MongoDB

Bước 2: User Input

Nhận text prompt từ user (CLI / notebook / web)

Optional: nhận image upload

Chuyển input thành embedding:

Text → CLIP text encoder

Image → CLIP image encoder

Bước 3: Search top-k images

Query FAISS index với embedding

Lấy top-k ảnh và metadata

Hiển thị cho user chọn (notebook: matplotlib, web: HTML gallery)

Bước 4: User Selection

User chọn 1 hoặc nhiều ảnh

Lưu list selected image paths

Bước 5: GroundingDINO Detection

Load pretrained GroundingDINO model

Với mỗi ảnh được chọn:

Truyền image + prompt text

Output: bounding boxes + confidence scores

Optional: filter boxes theo threshold (e.g., 0.5)

Bước 6: SAM Segmentation

Load SAM model

Với mỗi bounding box:

Feed box vào SAM → mask binary

Merge masks nếu cần (nhiều boxes → 1 mask per object)

Bước 7: Post-Processing / Output

Tách foreground ra:

mask * image → alpha channel

Background:

Blur, remove, or keep original

Save output ảnh: outputs/

Update metadata / database nếu muốn lưu user selection

Bước 8: Optional UI / Download

Notebook → show images + masks + download button

Web UI: FastAPI + Jinja2 → gallery + download

API endpoint: /search, /segment, /download

Tips khi code

Module hóa: chia file thành search.py, segment.py, utils.py, db.py

Logging: dùng tqdm hoặc logging để track progress

Cache embeddings / FAISS index: tránh build lại mỗi lần chạy

Test nhỏ trước: 5–10 ảnh, 1 prompt, sau đó scale dataset